{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"jumbotron\">\n",
    "  <h1><i class=\"fa fa-bar-chart\" aria-hidden=\"true\"></i> Modelado de datos</h1>\n",
    "  <p></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metodos leer y guardar PICKLE\n",
    "from pickle import load, dump\n",
    "\n",
    "# Métodos para RL\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score,roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#Métodos MLFlow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Métodos pandas y numpy\n",
    "from numpy import exp\n",
    "from numpy import logspace\n",
    "from numpy import random\n",
    "from numpy import mean\n",
    "from numpy import max\n",
    "from numpy import arange\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "\n",
    "\n",
    "# Métodos para Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "with open('Data/data_engi_v1.pickle', 'rb') as handle:\n",
    "    df = load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2009-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0.691208</td>\n",
       "      <td>1.575298</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>1.655518</td>\n",
       "      <td>1.214537</td>\n",
       "      <td>11</td>\n",
       "      <td>0.534126</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278186</td>\n",
       "      <td>1.563621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.017213</td>\n",
       "      <td>0.999852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769131</td>\n",
       "      <td>0.671504</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>2.099110</td>\n",
       "      <td>1.400800</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.290764</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318980</td>\n",
       "      <td>0.627467</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.999407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.924976</td>\n",
       "      <td>1.919600</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>1.360617</td>\n",
       "      <td>0.762183</td>\n",
       "      <td>5</td>\n",
       "      <td>0.384146</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.597921</td>\n",
       "      <td>1.783032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.997630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>1.314588</td>\n",
       "      <td>2.034368</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>1.528352</td>\n",
       "      <td>1.187928</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.740704</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.658823</td>\n",
       "      <td>1.885424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.996298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>4</td>\n",
       "      <td>1.673032</td>\n",
       "      <td>2.407362</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>1.490750</td>\n",
       "      <td>0.176784</td>\n",
       "      <td>14</td>\n",
       "      <td>-0.440744</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.343970</td>\n",
       "      <td>2.177972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.994671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56415</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>6</td>\n",
       "      <td>0.909391</td>\n",
       "      <td>1.317071</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>-1.318198</td>\n",
       "      <td>0.868619</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.440744</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958451</td>\n",
       "      <td>1.402719</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.337523</td>\n",
       "      <td>0.941317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56416</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>6</td>\n",
       "      <td>1.205497</td>\n",
       "      <td>1.202303</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>-0.178193</td>\n",
       "      <td>0.230002</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.290764</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004127</td>\n",
       "      <td>1.358837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.353676</td>\n",
       "      <td>0.935368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56417</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>6</td>\n",
       "      <td>1.127574</td>\n",
       "      <td>1.230995</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>-2.311520</td>\n",
       "      <td>0.868619</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.590724</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004127</td>\n",
       "      <td>1.373465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.369725</td>\n",
       "      <td>0.929141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56418</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>6</td>\n",
       "      <td>0.940560</td>\n",
       "      <td>1.087536</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>-1.096055</td>\n",
       "      <td>0.762183</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.115654</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.004127</td>\n",
       "      <td>0.949270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.385663</td>\n",
       "      <td>0.922640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56419</td>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>6</td>\n",
       "      <td>1.049652</td>\n",
       "      <td>1.073190</td>\n",
       "      <td>0.135801</td>\n",
       "      <td>-2.311520</td>\n",
       "      <td>0.788792</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.815694</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.095480</td>\n",
       "      <td>1.212563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.401488</td>\n",
       "      <td>0.915864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56420 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Location   MinTemp   MaxTemp  Rainfall  Evaporation  \\\n",
       "0     2009-01-01         4  0.691208  1.575298  0.135801     1.655518   \n",
       "1     2009-01-02         4  0.769131  0.671504  0.135801     2.099110   \n",
       "2     2009-01-04         4  0.924976  1.919600  0.135801     1.360617   \n",
       "3     2009-01-05         4  1.314588  2.034368  0.135801     1.528352   \n",
       "4     2009-01-06         4  1.673032  2.407362  0.135801     1.490750   \n",
       "...          ...       ...       ...       ...       ...          ...   \n",
       "56415 2017-06-20         6  0.909391  1.317071  0.135801    -1.318198   \n",
       "56416 2017-06-21         6  1.205497  1.202303  0.135801    -0.178193   \n",
       "56417 2017-06-22         6  1.127574  1.230995  0.135801    -2.311520   \n",
       "56418 2017-06-23         6  0.940560  1.087536  0.135801    -1.096055   \n",
       "56419 2017-06-24         6  1.049652  1.073190  0.135801    -2.311520   \n",
       "\n",
       "       Sunshine  WindGustDir  WindGustSpeed  WindDir9am  ...   Temp9am  \\\n",
       "0      1.214537           11       0.534126           1  ...  1.278186   \n",
       "1      1.400800            8      -0.290764          10  ...  0.318980   \n",
       "2      0.762183            5       0.384146           5  ...  1.597921   \n",
       "3      1.187928           14      -0.740704          14  ...  1.658823   \n",
       "4      0.176784           14      -0.440744           7  ...  2.343970   \n",
       "...         ...          ...            ...         ...  ...       ...   \n",
       "56415  0.868619            1      -0.440744           9  ...  0.958451   \n",
       "56416  0.230002            0      -0.290764           9  ...  1.004127   \n",
       "56417  0.868619            0      -0.590724           0  ...  1.004127   \n",
       "56418  0.762183            2      -1.115654           9  ...  1.004127   \n",
       "56419  0.788792            1      -0.815694           1  ...  1.095480   \n",
       "\n",
       "        Temp3pm  RainToday  RainTomorrow  month  day     month_sin  month_cos  \\\n",
       "0      1.563621          0             0      1    1  5.000000e-01   0.866025   \n",
       "1      0.627467          0             0      1    2  5.000000e-01   0.866025   \n",
       "2      1.783032          0             0      1    4  5.000000e-01   0.866025   \n",
       "3      1.885424          0             0      1    5  5.000000e-01   0.866025   \n",
       "4      2.177972          0             0      1    6  5.000000e-01   0.866025   \n",
       "...         ...        ...           ...    ...  ...           ...        ...   \n",
       "56415  1.402719          0             0      6   20  1.224647e-16  -1.000000   \n",
       "56416  1.358837          0             0      6   21  1.224647e-16  -1.000000   \n",
       "56417  1.373465          0             0      6   22  1.224647e-16  -1.000000   \n",
       "56418  0.949270          0             0      6   23  1.224647e-16  -1.000000   \n",
       "56419  1.212563          0             0      6   24  1.224647e-16  -1.000000   \n",
       "\n",
       "        day_sin   day_cos  \n",
       "0      0.017213  0.999852  \n",
       "1      0.034422  0.999407  \n",
       "2      0.068802  0.997630  \n",
       "3      0.085965  0.996298  \n",
       "4      0.103102  0.994671  \n",
       "...         ...       ...  \n",
       "56415  0.337523  0.941317  \n",
       "56416  0.353676  0.935368  \n",
       "56417  0.369725  0.929141  \n",
       "56418  0.385663  0.922640  \n",
       "56419  0.401488  0.915864  \n",
       "\n",
       "[56420 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminar variables superfluas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['month']\n",
    "del df['day']\n",
    "del df['Date']\n",
    "del df['day_sin']\n",
    "del df['day_cos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'RainTomorrow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[label]\n",
    "\n",
    "del df[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "#scaler.fit(X)\n",
    "#X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística\n",
    "\n",
    "\n",
    "Debido a que las biliotecas de Sklearn no cuenta con la opcón de vsualizar los `p-values` y los coeficientes de la regresión en forma de tabla como lo hace la bilioteca `statsmodels` iniciaremos con un análisis utilizando dicha biblioteca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.357605\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:           RainTomorrow   No. Observations:                56420\n",
      "Model:                          Logit   Df Residuals:                    56397\n",
      "Method:                           MLE   Df Model:                           22\n",
      "Date:                Thu, 05 Aug 2021   Pseudo R-squ.:                  0.3217\n",
      "Time:                        11:53:55   Log-Likelihood:                -20176.\n",
      "converged:                       True   LL-Null:                       -29747.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0632      0.002    -41.569      0.000      -0.066      -0.060\n",
      "x2            -0.2399      0.046     -5.266      0.000      -0.329      -0.151\n",
      "x3             0.2101      0.082      2.569      0.010       0.050       0.370\n",
      "x4             0.0596      0.011      5.225      0.000       0.037       0.082\n",
      "x5            -0.0085      0.014     -0.613      0.540      -0.036       0.019\n",
      "x6            -0.5589      0.023    -24.716      0.000      -0.603      -0.515\n",
      "x7            -0.0121      0.004     -3.313      0.001      -0.019      -0.005\n",
      "x8             0.8276      0.021     39.610      0.000       0.787       0.869\n",
      "x9            -0.0720      0.003    -23.459      0.000      -0.078      -0.066\n",
      "x10           -0.0526      0.004    -14.798      0.000      -0.060      -0.046\n",
      "x11           -0.1582      0.017     -9.262      0.000      -0.192      -0.125\n",
      "x12           -0.1735      0.018     -9.474      0.000      -0.209      -0.138\n",
      "x13            0.0985      0.028      3.559      0.000       0.044       0.153\n",
      "x14            1.1305      0.033     34.120      0.000       1.066       1.195\n",
      "x15           -0.0172      0.058     -0.296      0.767      -0.131       0.097\n",
      "x16           -0.4035      0.057     -7.032      0.000      -0.516      -0.291\n",
      "x17           -0.0794      0.020     -3.940      0.000      -0.119      -0.040\n",
      "x18            0.2391      0.020     11.790      0.000       0.199       0.279\n",
      "x19           -0.1073      0.069     -1.549      0.121      -0.243       0.028\n",
      "x20            0.0485      0.091      0.532      0.595      -0.130       0.227\n",
      "x21            0.3199      0.032     10.079      0.000       0.258       0.382\n",
      "x22           -0.0617      0.021     -2.934      0.003      -0.103      -0.020\n",
      "x23            0.0094      0.024      0.398      0.690      -0.037       0.056\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(Y,X.astype(float))\n",
    "result=logit_model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos obervar que existen variables como `x5,x15,x20` y `x23` que no aportan información util al modelado y debería ser eliminadas. Es decir no son significativas por tener valores `p` mayores a 0.05\n",
    "\n",
    "Los coeficientes de la regresión sólo muetras si cada variable suma o resta a la probabilidad de que llueva el dia de mañana. Para saber el peso que aporta cada variable o poder predictivo analizaramos los `odds ratios`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           5%       95%  Odds Ratio\n",
      "x1   0.936006  0.941597    0.938797\n",
      "x2   0.719546  0.860200    0.786736\n",
      "x3   1.051033  1.448291    1.233775\n",
      "x4   1.037972  1.085473    1.061457\n",
      "x5   0.965022  1.018807    0.991550\n",
      "x6   0.547019  0.597726    0.571811\n",
      "x7   0.980970  0.995083    0.988001\n",
      "x8   2.195937  2.383347    2.287724\n",
      "x9   0.924907  0.936109    0.930491\n",
      "x10  0.942142  0.955368    0.948732\n",
      "x11  0.825584  0.882749    0.853688\n",
      "x12  0.811042  0.871418    0.840688\n",
      "x13  1.045273  1.165082    1.103553\n",
      "x14  2.902487  3.305032    3.097227\n",
      "x15  0.876867  1.101752    0.982899\n",
      "x16  0.596965  0.747513    0.668011\n",
      "x17  0.887877  0.960872    0.923653\n",
      "x18  1.220621  1.321619    1.270117\n",
      "x19  0.784276  1.028842    0.898274\n",
      "x20  0.877779  1.255300    1.049703\n",
      "x21  1.293909  1.465309    1.376945\n",
      "x22  0.902251  0.979737    0.940197\n",
      "x23  0.963830  1.057212    1.009442\n"
     ]
    }
   ],
   "source": [
    "params = result.params\n",
    "conf = result.conf_int()\n",
    "conf['Odds Ratio'] = params\n",
    "conf.columns = ['5%', '95%', 'Odds Ratio']\n",
    "print(exp(conf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Podemos vizualizar los invervalos de confianza ( los cuales su discución queda fuera del alcance debido al  tiempo) y los `odds ratio`.\n",
    "- Los cuales nos dicen que la variable `x14` y `x8` son las de mayor aporte a la predicción positiva (que llueva) y es una propabilidad de 3 a 1 y de 2.2 a 1 respectivamente.\n",
    "\n",
    "- Las los `odds ratios` con valores inferiores a .7 corresponden a las variable `x16` y `x6`, los cuales restan probabilidad a la premisa de que llovera mañana \n",
    "\n",
    "- El resto de valores de los `odds ratios` estan cercanos a 1 , lo cual no indica que el incremento/decremento en el valor de dichas variables incrementa/resta la propabilidad de que llueva mañana en una escala 1:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora entrenaremos un modelo y mediremos su rendimiento con la métrica accuracy y ROC. Se utilizara la biblioteca MLFlow para la administración de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir los parámetros de búsqueda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\"\n",
    "    Encuentre el punto de corte de probabilidad óptimo para un modelo de clasificación relacionado con la tasa de eventos\n",
    "\n",
    "     Input:\n",
    "   \n",
    "         target: \n",
    "                 Matriz con las verdaderas etiquetas de clase, donde las filas son observaciones\n",
    "\n",
    "         predicted: \n",
    "                 Matriz con datos predichos, donde las filas son observaciones\n",
    "\n",
    "    Output :\n",
    "                \n",
    "        list type: con valor óptimo de corte\n",
    "    \"\"\"\n",
    "    \n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = arange(len(tpr)) \n",
    "    roc = DataFrame({'tf' : Series(tpr-(1-fpr), index=i), 'threshold' : Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 9\n",
    "random.seed(seed)\n",
    "num_folds = 5\n",
    "\n",
    "#Hiperparámetros\n",
    "anomaly_weights = [1,2,4, 5, 7, 10, 15]\n",
    "penalty = ['l1', 'l2', 'elasticnet']\n",
    "C = logspace(-3,3,7)\n",
    "\n",
    "\n",
    "# define 10-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits= 10, shuffle=True, random_state=seed)\n",
    "logs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sólo se hara un búsqueda para los pesos óptimos de las clases, debido al problema de clases desvalanceadas, los demás hiperparámetros se dejan para un segundo sprint por falta de tiempo ya que los datos son de alta dimensión y con muestras arriba de 50 mil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'sklearn_RL_02' does not exist. Creating a new experiment\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4150  250]\n",
      " [ 553  690]]\n",
      "AUC: 0.7491452131938857\n",
      "eval_acc: 0.8576998050682261\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4157  243]\n",
      " [ 557  686]]\n",
      "AUC: 0.7483316572807723\n",
      "eval_acc: 0.8582314371788056\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4164  236]\n",
      " [ 586  657]]\n",
      "AUC: 0.7374617860016092\n",
      "eval_acc: 0.8543328017012227\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4144  255]\n",
      " [ 585  658]]\n",
      "AUC: 0.7356983604662582\n",
      "eval_acc: 0.8511166253101737\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4162  237]\n",
      " [ 571  672]]\n",
      "AUC: 0.7433758165984113\n",
      "eval_acc: 0.8567883729174052\n",
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4133  266]\n",
      " [ 579  664]]\n",
      "AUC: 0.7368615919986203\n",
      "eval_acc: 0.8502304147465438\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4136  263]\n",
      " [ 558  685]]\n",
      "AUC: 0.7456498834939631\n",
      "eval_acc: 0.8544842254519673\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4172  227]\n",
      " [ 589  653]]\n",
      "AUC: 0.7370811291835834\n",
      "eval_acc: 0.8553447970218047\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4136  263]\n",
      " [ 589  653]]\n",
      "AUC: 0.7329892901292528\n",
      "eval_acc: 0.8489629498315902\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  1\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[4140  259]\n",
      " [ 588  654]]\n",
      "AUC: 0.7338465154026003\n",
      "eval_acc: 0.8498493174968977\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.8537040746724637\n",
      "AUC:  0.7400441243748956\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.8582314371788056\n",
      "AUC:  0.7491452131938857\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3927  473]\n",
      " [ 390  853]]\n",
      "AUC: 0.7893714802896218\n",
      "eval_acc: 0.8470671628566365\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3897  503]\n",
      " [ 401  842]]\n",
      "AUC: 0.7815376106194691\n",
      "eval_acc: 0.8398015240120503\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3917  483]\n",
      " [ 413  830]]\n",
      "AUC: 0.7789833065164925\n",
      "eval_acc: 0.8412192096402623\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3862  537]\n",
      " [ 436  807]]\n",
      "AUC: 0.763581260788993\n",
      "eval_acc: 0.8275434243176178\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3885  514]\n",
      " [ 393  850]]\n",
      "AUC: 0.7834923537255323\n",
      "eval_acc: 0.8392414037575328\n",
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3879  520]\n",
      " [ 405  838]]\n",
      "AUC: 0.7779833491741066\n",
      "eval_acc: 0.8360510457284651\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3891  508]\n",
      " [ 362  881]]\n",
      "AUC: 0.7966441579551559\n",
      "eval_acc: 0.8457993619283942\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3930  469]\n",
      " [ 399  843]]\n",
      "AUC: 0.7860644107740781\n",
      "eval_acc: 0.8461265733026059\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3888  511]\n",
      " [ 410  832]]\n",
      "AUC: 0.7768622571591626\n",
      "eval_acc: 0.8367310760503457\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  2\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3855  544]\n",
      " [ 391  851]]\n",
      "AUC: 0.78076035799382\n",
      "eval_acc: 0.8342492465874844\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.8393830028181395\n",
      "AUC:  0.7815280544996431\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.8470671628566365\n",
      "AUC:  0.7966441579551559\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3527  873]\n",
      " [ 225 1018]]\n",
      "AUC: 0.8102886162510056\n",
      "eval_acc: 0.8054226475279107\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3509  891]\n",
      " [ 245  998]]\n",
      "AUC: 0.8001981094127112\n",
      "eval_acc: 0.798688640793904\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3511  889]\n",
      " [ 239 1004]]\n",
      "AUC: 0.8028388978278359\n",
      "eval_acc: 0.8001063264221159\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3465  934]\n",
      " [ 245  998]]\n",
      "AUC: 0.7952876183920246\n",
      "eval_acc: 0.7910315490960652\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3478  921]\n",
      " [ 234 1009]]\n",
      "AUC: 0.8011900057004838\n",
      "eval_acc: 0.7952853598014888\n",
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3463  936]\n",
      " [ 242 1001]]\n",
      "AUC: 0.7962670518440433\n",
      "eval_acc: 0.7912087912087912\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3507  892]\n",
      " [ 181 1062]]\n",
      "AUC: 0.8258055979591647\n",
      "eval_acc: 0.8098192130450195\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3527  872]\n",
      " [ 244  998]]\n",
      "AUC: 0.8026579016823836\n",
      "eval_acc: 0.8021627371033505\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3446  953]\n",
      " [ 246  996]]\n",
      "AUC: 0.7926461108310738\n",
      "eval_acc: 0.7874490338592448\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  4\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3430  969]\n",
      " [ 232 1010]]\n",
      "AUC: 0.796463586549278\n",
      "eval_acc: 0.7870944867931218\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.7968268785651011\n",
      "AUC:  0.8023643496450005\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.8098192130450195\n",
      "AUC:  0.8258055979591647\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3369 1031]\n",
      " [ 189 1054]]\n",
      "AUC: 0.806815164923572\n",
      "eval_acc: 0.7838029416976785\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3371 1029]\n",
      " [ 195 1048]]\n",
      "AUC: 0.8046289219629927\n",
      "eval_acc: 0.7830940988835726\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3364 1036]\n",
      " [ 195 1048]]\n",
      "AUC: 0.8038334674175381\n",
      "eval_acc: 0.7818536239588871\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3304 1095]\n",
      " [ 208 1035]]\n",
      "AUC: 0.7918713515852447\n",
      "eval_acc: 0.7690535271180432\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3307 1092]\n",
      " [ 194 1049]]\n",
      "AUC: 0.7978438747780935\n",
      "eval_acc: 0.772066643034385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcssa\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\mcssa\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3306 1093]\n",
      " [ 199 1044]]\n",
      "AUC: 0.7957189495089299\n",
      "eval_acc: 0.7710031903580291\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3350 1049]\n",
      " [ 156 1087]]\n",
      "AUC: 0.8180169485604953\n",
      "eval_acc: 0.7864232541651897\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3363 1036]\n",
      " [ 199 1043]]\n",
      "AUC: 0.8021332435749745\n",
      "eval_acc: 0.7810671866690303\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3289 1110]\n",
      " [ 199 1043]]\n",
      "AUC: 0.793722241074406\n",
      "eval_acc: 0.7679489452224783\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  5\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3248 1151]\n",
      " [ 181 1061]]\n",
      "AUC: 0.7963084678519017\n",
      "eval_acc: 0.7638716539620635\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.7760185065069358\n",
      "AUC:  0.8010892631238148\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.7864232541651897\n",
      "AUC:  0.8180169485604953\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3085 1315]\n",
      " [ 123 1120]]\n",
      "AUC: 0.8010911102172165\n",
      "eval_acc: 0.745171008328903\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3108 1292]\n",
      " [ 141 1102]]\n",
      "AUC: 0.7964641995172969\n",
      "eval_acc: 0.7460570618465355\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3083 1317]\n",
      " [ 147 1096]]\n",
      "AUC: 0.7912097747385358\n",
      "eval_acc: 0.7405635300372142\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3018 1381]\n",
      " [ 162 1081]]\n",
      "AUC: 0.7778675838160395\n",
      "eval_acc: 0.7265154200638072\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3019 1380]\n",
      " [ 137 1106]]\n",
      "AUC: 0.788037561378043\n",
      "eval_acc: 0.7311237149946828\n",
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3042 1357]\n",
      " [ 141 1102]]\n",
      "AUC: 0.7890427814264086\n",
      "eval_acc: 0.7344913151364765\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3064 1335]\n",
      " [ 109 1134]]\n",
      "AUC: 0.8044154334059321\n",
      "eval_acc: 0.7440623892236795\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3092 1307]\n",
      " [ 143 1099]]\n",
      "AUC: 0.7938750718853904\n",
      "eval_acc: 0.7429533770608048\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3014 1385]\n",
      " [ 148 1094]]\n",
      "AUC: 0.7829965381533426\n",
      "eval_acc: 0.7282396738166992\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  7\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[3007 1392]\n",
      " [ 129 1113]]\n",
      "AUC: 0.7898498560827945\n",
      "eval_acc: 0.7303669562134373\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.736954444672224\n",
      "AUC:  0.7914849910620999\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.7460570618465355\n",
      "AUC:  0.8044154334059321\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2742 1658]\n",
      " [  83 1160]]\n",
      "AUC: 0.7782039420756235\n",
      "eval_acc: 0.6914761651603757\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2783 1617]\n",
      " [  93 1150]]\n",
      "AUC: 0.7788405068382945\n",
      "eval_acc: 0.696969696969697\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2735 1665]\n",
      " [ 100 1143]]\n",
      "AUC: 0.770570193081255\n",
      "eval_acc: 0.6872231082757398\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2676 1723]\n",
      " [ 110 1133]]\n",
      "AUC: 0.7599122487612832\n",
      "eval_acc: 0.6751152073732719\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2685 1714]\n",
      " [ 100 1143]]\n",
      "AUC: 0.7649577346712857\n",
      "eval_acc: 0.6784828075150656\n",
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2711 1688]\n",
      " [  93 1150]]\n",
      "AUC: 0.7707287200685742\n",
      "eval_acc: 0.684331797235023\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2711 1688]\n",
      " [  67 1176]]\n",
      "AUC: 0.781187288049266\n",
      "eval_acc: 0.6889400921658986\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2753 1646]\n",
      " [  97 1145]]\n",
      "AUC: 0.7738621059756299\n",
      "eval_acc: 0.6910122318737812\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2671 1728]\n",
      " [  94 1148]]\n",
      "AUC: 0.7657495353760315\n",
      "eval_acc: 0.6770076227619216\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  10\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2686 1713]\n",
      " [  94 1148]]\n",
      "AUC: 0.7674544683153359\n",
      "eval_acc: 0.6796667257578444\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.6850225455088619\n",
      "AUC:  0.7711466743212579\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.696969696969697\n",
      "AUC:  0.781187288049266\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "----------------------------------------fold:  1\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2280 2120]\n",
      " [  46 1197]]\n",
      "AUC: 0.7405872888173773\n",
      "eval_acc: 0.6161616161616161\n",
      "----------------------------------------fold:  2\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2362 2038]\n",
      " [  62 1181]]\n",
      "AUC: 0.7434694288012873\n",
      "eval_acc: 0.6278575225943647\n",
      "----------------------------------------fold:  3\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2341 2059]\n",
      " [  65 1178]]\n",
      "AUC: 0.7398763073209975\n",
      "eval_acc: 0.6236044657097288\n",
      "----------------------------------------fold:  4\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2297 2102]\n",
      " [  67 1176]]\n",
      "AUC: 0.7341311389244649\n",
      "eval_acc: 0.6155618574973414\n",
      "----------------------------------------fold:  5\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2276 2123]\n",
      " [  60 1183]]\n",
      "AUC: 0.7345600011119328\n",
      "eval_acc: 0.6130804679191776\n",
      "----------------------------------------fold:  6\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2335 2064]\n",
      " [  51 1192]]\n",
      "AUC: 0.7448863442049747\n",
      "eval_acc: 0.6251329315845445\n",
      "----------------------------------------fold:  7\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2291 2108]\n",
      " [  41 1202]]\n",
      "AUC: 0.743907733729435\n",
      "eval_acc: 0.6191066997518611\n",
      "----------------------------------------fold:  8\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2312 2087]\n",
      " [  57 1185]]\n",
      "AUC: 0.7398401371414013\n",
      "eval_acc: 0.6199255451161142\n",
      "----------------------------------------fold:  9\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2254 2145]\n",
      " [  64 1178]]\n",
      "AUC: 0.7304296943493599\n",
      "eval_acc: 0.6084027654671158\n",
      "----------------------------------------fold:  10\n",
      "Anomaly Weight:  15\n",
      "threshold:  1\n",
      "Aplicar el threshold correcto ...\n",
      "Confusion Matrix\n",
      "[[2289 2110]\n",
      " [  55 1187]]\n",
      "AUC: 0.7380310596135338\n",
      "eval_acc: 0.6162028009218223\n",
      "\n",
      "Averages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.6185036672723687\n",
      "AUC:  0.7389719134014765\n",
      "Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \n",
      "Accuracy:  0.6278575225943647\n",
      "AUC:  0.7448863442049747\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"sklearn_RL_02\")\n",
    "\n",
    "\n",
    "for f in range(len(anomaly_weights)): #Búsqueda del peso de las clases \n",
    "\n",
    "    fold = 1\n",
    "    accuracies = []\n",
    "    auc_scores= []\n",
    "\n",
    "\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, Y):\n",
    "\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            weight = anomaly_weights[f]\n",
    "            mlflow.log_param(\"anomaly_weight\", weight)\n",
    "            class_weights= {\n",
    "                0: 1,\n",
    "                1: weight\n",
    "                            }\n",
    "            #-------------------------------------------------------------------<definir modelo>\n",
    "            #definir modelos con los parámetros\n",
    "            sk_model = LogisticRegression(\n",
    "                                    random_state=None,\n",
    "                                    max_iter=400,\n",
    "                                    solver='newton-cg',\n",
    "                                    class_weight=class_weights\n",
    "                                            )\n",
    "            #-------------------------------------------------------------------<entrenar modelo>\n",
    "            #Entrenar el modelo\n",
    "            sk_model.fit(X_train, y_train)\n",
    "\n",
    "            #Separador \n",
    "            for h in range(40): print('-', end=\"\")\n",
    "            #------------------------------------------------\n",
    "\n",
    "            print(\"fold: \",fold)\n",
    "            print(\"Anomaly Weight: \", weight)\n",
    "\n",
    "            #--------------------------------------------------------------------<Score train>\n",
    "            #Obtner métrica accuracy con el train\n",
    "            train_acc = sk_model.score(X_train, y_train)\n",
    "            #Guardar métrica accuracy\n",
    "            mlflow.log_metric(\"train_acc\", train_acc)\n",
    "\n",
    "            \n",
    "            #--------------------------------------------------------------------<Score test>\n",
    "            #Obtner métrica accuracy con el test\n",
    "            eval_acc = sk_model.score(X_test, y_test)\n",
    "            #Guardar métrica accuracy con el test\n",
    "            mlflow.log_metric(\"eval_acc\", eval_acc)\n",
    "\n",
    "            #--------------------------------------------------------------------< Buscar el threshold óptimo>\n",
    "            #obtener la probabilidad\n",
    "            preds = sk_model.predict(X_test)\n",
    "\n",
    "            \n",
    "            threshold = Find_Optimal_Cutoff(y_test, preds)\n",
    "            print(\"threshold: \", threshold[0])\n",
    "            #cv_thresholds.extend(threshold)\n",
    "            mlflow.log_metric(\"threshold\", threshold[0])\n",
    "\n",
    "            print(\"Aplicar el threshold correcto ...\")\n",
    "    \n",
    "            y_pred = (sk_model.predict_proba(X_test)[:,1] > threshold[0]).astype(bool) # set threshold as 0.3\n",
    " \n",
    "        \n",
    "            acc = accuracy_score(y_test, preds)\n",
    "            mlflow.log_metric(\"threshold_eval_acc\", acc)\n",
    "            \n",
    "            #--------------------------------------------------------------------<Score con el threshold óptimo>\n",
    "            \n",
    "            cm = confusion_matrix(y_test, preds)\n",
    "            print (\"Confusion Matrix\")\n",
    "            print (cm)\n",
    "            \n",
    "            \n",
    "            #---------------------------------------------------------------------<Obtener roc con el threshold óptimo>\n",
    "            #Obtner la ROC\n",
    "            try:\n",
    "                auc_score = roc_auc_score(y_test,  sk_model.predict(X_test))\n",
    "            except:\n",
    "                auc_score = -1\n",
    "\n",
    "                \n",
    "            #----------------------------------------------------------------------<almacenar resultados>\n",
    "            #Guardar el valor de ROC\n",
    "            mlflow.log_metric(\"auc_score\", auc_score)\n",
    "\n",
    "            print(\"AUC: {}\\neval_acc: {}\".format(auc_score, eval_acc))\n",
    "\n",
    "            #Agregar el valor del accuracy y la roc en la lista\n",
    "            accuracies.append(eval_acc)\n",
    "            auc_scores.append(auc_score)\n",
    "\n",
    "            #Almacenar en un sólo objeto el modelo , el test , las etiquetas del test y la probabilidades (predicts)\n",
    "            log = [sk_model, X_test, y_test, preds]\n",
    "            #Agregar a la lista\n",
    "            logs.append(log)\n",
    "\n",
    "            #Almacenar del modelo con el peso de clases  y el fold correspondiente\n",
    "            mlflow.sklearn.log_model(sk_model, f\"anom_weight_{weight}_fold_{fold}\")\n",
    "\n",
    "            fold = fold + 1\n",
    "\n",
    "            mlflow.end_run()\n",
    "\n",
    "    print(\"\\nAverages::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \")\n",
    "    print(\"Accuracy: \", mean(accuracies))\n",
    "    print(\"AUC: \", mean(auc_scores))\n",
    "    print(\"Best::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::. \")\n",
    "    print(\"Accuracy: \", max(accuracies))\n",
    "    print(\"AUC: \", max(auc_scores))\n",
    "    print(\"\\n\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los resultados de MLFlow si ejecutamos en la terminal:\n",
    "\n",
    "\n",
    "\n",
    " _mlflow ui -p 1234_\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiementaremos con un algortimos basados en vecindades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'metric': ['euclidean', 'manhattan'], 'n_jobs': [-1],\n",
       "                         'n_neighbors': [1, 3, 5, 7, 9, 11],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the model and parameters\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':[1,3,5,7,9,11],\n",
    "              #'leaf_size':[1,3,5],\n",
    "              'metric':['euclidean','manhattan'],\n",
    "              'weights':['uniform','distance'],\n",
    "              #'algorithm':['auto', 'kd_tree'],\n",
    "              'n_jobs':[-1]\n",
    "             }\n",
    "\n",
    "#Fit the model\n",
    "model = GridSearchCV(knn, param_grid=parameters, cv=3)\n",
    "model.fit(X,Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados de la búsqueda son :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_jobs': -1, 'n_neighbors': 7, 'weights': 'distance'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031017369727047"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con `k-NN` se esperaban resultados similares a `RL`. La lógica incial es que k-NN calcula un conjunto de pesos locales (sus k vecinos) y va de acorde a la premisa de que `sí` lloverá mañana tomando en cuenta las características del clima de hoy (y posible días anteriore) son condiciones mas locales que generales.\n",
    "El modelo refuta esta idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como se comporta las métricas restantes (matriz de confusión y ROC ) utilizando validación cruzada con los mejores hiperparámetros obtenidos en la búsqueda de malla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuera del alcance por falta de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
